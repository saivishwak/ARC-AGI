{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c319ba02-ecd1-438c-a553-4cf14df7aa97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in /home/vishwak/Desktop/projects/ARC-AGI/.env/lib/python3.12/site-packages (0.31.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/vishwak/Desktop/projects/ARC-AGI/.env/lib/python3.12/site-packages (from accelerate) (2.0.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/vishwak/Desktop/projects/ARC-AGI/.env/lib/python3.12/site-packages (from accelerate) (24.1)\n",
      "Requirement already satisfied: psutil in /home/vishwak/Desktop/projects/ARC-AGI/.env/lib/python3.12/site-packages (from accelerate) (5.9.8)\n",
      "Requirement already satisfied: pyyaml in /home/vishwak/Desktop/projects/ARC-AGI/.env/lib/python3.12/site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /home/vishwak/Desktop/projects/ARC-AGI/.env/lib/python3.12/site-packages (from accelerate) (2.3.1+cu121)\n",
      "Requirement already satisfied: huggingface-hub in /home/vishwak/Desktop/projects/ARC-AGI/.env/lib/python3.12/site-packages (from accelerate) (0.23.4)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/vishwak/Desktop/projects/ARC-AGI/.env/lib/python3.12/site-packages (from accelerate) (0.4.3)\n",
      "Requirement already satisfied: filelock in /home/vishwak/Desktop/projects/ARC-AGI/.env/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /home/vishwak/Desktop/projects/ARC-AGI/.env/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (4.9.0)\n",
      "Requirement already satisfied: sympy in /home/vishwak/Desktop/projects/ARC-AGI/.env/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /home/vishwak/Desktop/projects/ARC-AGI/.env/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/vishwak/Desktop/projects/ARC-AGI/.env/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /home/vishwak/Desktop/projects/ARC-AGI/.env/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (2024.2.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/vishwak/Desktop/projects/ARC-AGI/.env/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/vishwak/Desktop/projects/ARC-AGI/.env/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/vishwak/Desktop/projects/ARC-AGI/.env/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/vishwak/Desktop/projects/ARC-AGI/.env/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/vishwak/Desktop/projects/ARC-AGI/.env/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/vishwak/Desktop/projects/ARC-AGI/.env/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/vishwak/Desktop/projects/ARC-AGI/.env/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/vishwak/Desktop/projects/ARC-AGI/.env/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/vishwak/Desktop/projects/ARC-AGI/.env/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /home/vishwak/Desktop/projects/ARC-AGI/.env/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/vishwak/Desktop/projects/ARC-AGI/.env/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/vishwak/Desktop/projects/ARC-AGI/.env/lib/python3.12/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: requests in /home/vishwak/Desktop/projects/ARC-AGI/.env/lib/python3.12/site-packages (from huggingface-hub->accelerate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/vishwak/Desktop/projects/ARC-AGI/.env/lib/python3.12/site-packages (from huggingface-hub->accelerate) (4.66.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/vishwak/Desktop/projects/ARC-AGI/.env/lib/python3.12/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/vishwak/Desktop/projects/ARC-AGI/.env/lib/python3.12/site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/vishwak/Desktop/projects/ARC-AGI/.env/lib/python3.12/site-packages (from requests->huggingface-hub->accelerate) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/vishwak/Desktop/projects/ARC-AGI/.env/lib/python3.12/site-packages (from requests->huggingface-hub->accelerate) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/vishwak/Desktop/projects/ARC-AGI/.env/lib/python3.12/site-packages (from requests->huggingface-hub->accelerate) (2024.6.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/vishwak/Desktop/projects/ARC-AGI/.env/lib/python3.12/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: wandb in /home/vishwak/Desktop/projects/ARC-AGI/.env/lib/python3.12/site-packages (0.17.2)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /home/vishwak/Desktop/projects/ARC-AGI/.env/lib/python3.12/site-packages (from wandb) (8.1.7)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /home/vishwak/Desktop/projects/ARC-AGI/.env/lib/python3.12/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /home/vishwak/Desktop/projects/ARC-AGI/.env/lib/python3.12/site-packages (from wandb) (3.1.43)\n",
      "Requirement already satisfied: platformdirs in /home/vishwak/Desktop/projects/ARC-AGI/.env/lib/python3.12/site-packages (from wandb) (4.2.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<6,>=3.19.0 in /home/vishwak/Desktop/projects/ARC-AGI/.env/lib/python3.12/site-packages (from wandb) (5.27.1)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /home/vishwak/Desktop/projects/ARC-AGI/.env/lib/python3.12/site-packages (from wandb) (5.9.8)\n",
      "Requirement already satisfied: pyyaml in /home/vishwak/Desktop/projects/ARC-AGI/.env/lib/python3.12/site-packages (from wandb) (6.0.1)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /home/vishwak/Desktop/projects/ARC-AGI/.env/lib/python3.12/site-packages (from wandb) (2.32.3)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /home/vishwak/Desktop/projects/ARC-AGI/.env/lib/python3.12/site-packages (from wandb) (2.5.1)\n",
      "Requirement already satisfied: setproctitle in /home/vishwak/Desktop/projects/ARC-AGI/.env/lib/python3.12/site-packages (from wandb) (1.3.3)\n",
      "Requirement already satisfied: setuptools in /home/vishwak/Desktop/projects/ARC-AGI/.env/lib/python3.12/site-packages (from wandb) (70.0.0)\n",
      "Requirement already satisfied: six>=1.4.0 in /home/vishwak/Desktop/projects/ARC-AGI/.env/lib/python3.12/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/vishwak/Desktop/projects/ARC-AGI/.env/lib/python3.12/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/vishwak/Desktop/projects/ARC-AGI/.env/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/vishwak/Desktop/projects/ARC-AGI/.env/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/vishwak/Desktop/projects/ARC-AGI/.env/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/vishwak/Desktop/projects/ARC-AGI/.env/lib/python3.12/site-packages (from requests<3,>=2.0.0->wandb) (2024.6.2)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/vishwak/Desktop/projects/ARC-AGI/.env/lib/python3.12/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install -q -U -i https://pypi.org/simple/ bitsandbytes\n",
    "!pip install -q -U trl\n",
    "!pip install -q -U peft\n",
    "!pip install accelerate\n",
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "92ba4870-70ab-484c-9ff5-9357b0a1aa06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For dataset\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import ast\n",
    "import re\n",
    "import numpy as np\n",
    "from datasets import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# For LLM\n",
    "from peft import LoraConfig, PeftModel\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    "    set_seed,\n",
    "    pipeline\n",
    ")\n",
    "from trl import SFTTrainer, setup_chat_format, SFTConfig\n",
    "\n",
    "import torch\n",
    "from time import time\n",
    "\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from subprocess import Popen, PIPE, STDOUT\n",
    "from glob import glob\n",
    "\n",
    "# For wandb\n",
    "#from kaggle_secrets import UserSecretsClient\n",
    "import wandb \n",
    "# Set seed\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61fb7ba8-d9cf-43aa-b051-24dd4dfee6d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HF_TOKEN found\n"
     ]
    }
   ],
   "source": [
    "hf_token = os.getenv('HF_TOKEN')\n",
    "\n",
    "# Check if HF_TOKEN is found\n",
    "if hf_token:\n",
    "    print(\"HF_TOKEN found\")\n",
    "else:\n",
    "    print(\"HF_TOKEN is not set or found in environment variables.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77d76879-10e6-4cae-91ed-cfec9c633722",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path='../data/'\n",
    "# Loading JSON data\n",
    "def load_json(file_path):\n",
    "    data = {};\n",
    "    for file in glob(file_path+ \"*.json\"):\n",
    "        with open(file) as f:\n",
    "            file_name = os.path.basename(file).split(\".json\")[0]\n",
    "            data[file_name] = json.load(f)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97d6349e-dc45-42b7-8a77-5915b211e445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading files\n",
    "challenges =  load_json(base_path +'training/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b39d1fe-a144-41e4-bf09-f82bbcd0a61e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2dc579da'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(challenges)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13f3d00d-6d8f-411d-a41b-13edb0b7e2e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    file_name                                              train  \\\n",
      "0    2dc579da  [{'input': [[8, 8, 3, 8, 8], [8, 8, 3, 8, 8], ...   \n",
      "1    93b581b8  [{'input': [[0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0...   \n",
      "2    36d67576  [{'input': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
      "3    0ca9ddb6  [{'input': [[0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0...   \n",
      "4    496994bd  [{'input': [[2, 2, 2], [2, 2, 2], [3, 3, 3], [...   \n",
      "..        ...                                                ...   \n",
      "395  90f3ed37  [{'input': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [8...   \n",
      "396  8eb1be9a  [{'input': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
      "397  2013d3e2  [{'input': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0...   \n",
      "398  a65b410d  [{'input': [[0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0...   \n",
      "399  fafffa47  [{'input': [[0, 9, 9], [0, 9, 9], [9, 9, 9], [...   \n",
      "\n",
      "                                            test_input  \\\n",
      "0    [[[1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1], [1,...   \n",
      "1    [[[0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0], [0, ...   \n",
      "2    [[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0...   \n",
      "3    [[[0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0,...   \n",
      "4    [[[3, 3, 3, 3, 3, 3], [5, 5, 5, 5, 5, 5], [5, ...   \n",
      "..                                                 ...   \n",
      "395  [[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 8, 8,...   \n",
      "396  [[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0,...   \n",
      "397  [[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0,...   \n",
      "398  [[[0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0,...   \n",
      "399  [[[9, 0, 9], [0, 0, 9], [9, 0, 9], [0, 1, 1], ...   \n",
      "\n",
      "                                           test_output  \\\n",
      "0    [{'output': [[1, 1, 1, 1, 1, 1], [1, 1, 1, 1, ...   \n",
      "1    [{'output': [[0, 0, 0, 0, 0, 0], [5, 5, 0, 0, ...   \n",
      "2    [{'output': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...   \n",
      "3    [{'output': [[0, 0, 0, 0, 0, 0, 0, 0, 0], [0, ...   \n",
      "4    [{'output': [[3, 3, 3, 3, 3, 3], [5, 5, 5, 5, ...   \n",
      "..                                                 ...   \n",
      "395  [{'output': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [...   \n",
      "396  [{'output': [[0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1,...   \n",
      "397    [{'output': [[0, 0, 0], [0, 4, 4], [8, 8, 3]]}]   \n",
      "398  [{'output': [[3, 3, 3, 3, 3, 3, 3, 0, 0], [3, ...   \n",
      "399    [{'output': [[0, 0, 0], [2, 0, 0], [0, 2, 0]]}]   \n",
      "\n",
      "                                                  test  \n",
      "0    [{'input': [[1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, ...  \n",
      "1    [{'input': [[0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0...  \n",
      "2    [{'input': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "3    [{'input': [[0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0...  \n",
      "4    [{'input': [[3, 3, 3, 3, 3, 3], [5, 5, 5, 5, 5...  \n",
      "..                                                 ...  \n",
      "395  [{'input': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0...  \n",
      "396  [{'input': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
      "397  [{'input': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0...  \n",
      "398  [{'input': [[0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0...  \n",
      "399  [{'input': [[9, 0, 9], [0, 0, 9], [9, 0, 9], [...  \n",
      "\n",
      "[400 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Prepare data for DataFrame\n",
    "# Load JSON data from the files\n",
    "# with open('/kaggle/input/arc-prize-2024/arc-agi_evaluation_challenges.json') as f:\n",
    "#     challenges = json.load(f)\n",
    "\n",
    "# with open('/kaggle/input/arc-prize-2024/arc-agi_evaluation_solutions.json') as f:\n",
    "#     solutions = json.load(f)\n",
    "\n",
    "data = []\n",
    "for file_name, grids in challenges.items():\n",
    "    train_grids = grids.get('train', [])\n",
    "    test_inputs = [item['input'] for item in grids.get('test', [])]\n",
    "    test_outputs = [item['output'] for item in grids.get('test', [])]\n",
    "\n",
    "    # Transform test grids to lists of dicts with 'output' key\n",
    "    test_outputs_transformed = [{'output': grid} for grid in test_outputs]\n",
    "    # Combine test inputs and outputs in alternating manner\n",
    "    combined_tests = []\n",
    "    for test_input, test_output in zip(test_inputs, test_outputs_transformed):\n",
    "        combined_tests.append({'input': test_input, 'output': test_output})\n",
    "    data.append({\n",
    "            'file_name': file_name,\n",
    "            'train': train_grids,\n",
    "            'test_input': test_inputs,\n",
    "            'test_output': test_outputs_transformed,\n",
    "            'test': combined_tests\n",
    "    })\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f41c557-5ffa-42e6-b70e-7acbf3a132cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Loading checkpoint shards: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:03<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepare model, tokenizer: 5.937 sec.\n"
     ]
    }
   ],
   "source": [
    "# Define a template for formatting chat messages with the Llama 3 model\n",
    "# This is model specific. Change it if you e.g. use Google's Gemma instead of Llama\n",
    "LLAMA_3_CHAT_TEMPLATE = \"\"\"{% set loop_messages = messages %}{% for message in loop_messages %}{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{% if add_generation_prompt %}{{ '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}{% endif %}\"\"\"\n",
    "\n",
    "# Set the data type for computations to float16, bfloat16 not supported on T4/P100\n",
    "compute_dtype = getattr(torch, \"float16\")\n",
    "\n",
    "# Configure the BitsAndBytes settings for 4-bit quantization to reduce memory usage\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,  # Enable 4-bit quantization\n",
    "    bnb_4bit_use_double_quant=True,  # Use double quantization for improved precision\n",
    "    bnb_4bit_quant_type=\"nf4\",  # Specify the quantization type\n",
    "    bnb_4bit_compute_dtype=compute_dtype,  # Set the computation data type\n",
    ")\n",
    "\n",
    "# Specify the model ID change this if you e.g. want to try with Google's Gemma\n",
    "#model_id = \"/kaggle/input/llama-3/transformers/8b-chat-hf/1\"\n",
    "model_id = \"meta-llama/Meta-Llama-3-8B-instruct\"\n",
    "\n",
    "# Load the tokenizer associated with the model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.pad_token = tokenizer.eos_token  # Set the padding token to the end-of-sequence token you could also introduce a special pad token but this is not needed.\n",
    "tokenizer.chat_template = LLAMA_3_CHAT_TEMPLATE  # Apply the chat message template\n",
    "\n",
    "# Record the start time to measure the loading duration\n",
    "time_start = time()\n",
    "\n",
    "# Load the pre-trained model with specified configurations\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    quantization_config=bnb_config,  # Apply the 4-bit quantization configuration\n",
    "    torch_dtype=compute_dtype,  # Set the data type for the model\n",
    "    use_cache=False,  # Disable caching to save memory\n",
    "    device_map='auto',  # Automatically map the model to available devices (e.g., GPUs)\n",
    "    token=hf_token\n",
    ")\n",
    "\n",
    "# Enable gradient checkpointing to reduce memory usage during backpropagation\n",
    "model.gradient_checkpointing_enable()\n",
    "\n",
    "# Record the end time and print the duration for preparing the model and tokenizer\n",
    "time_end = time()\n",
    "print(f\"Prepare model, tokenizer: {round(time_end-time_start, 3)} sec.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a5f9e863-50cb-4e77-8b7f-b9544ee855a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 320/320 [00:00<00:00, 2449.22 examples/s]\n",
      "Map: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 80/80 [00:00<00:00, 2618.70 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# The system_prompt defines the initial instructions for the model, setting the context for solving ARC tasks.\n",
    "system_prompt = '''You are a puzzle solving wizard. You are given a puzzle from the abstraction and reasoning corpus developed by Francois Chollet.'''\n",
    "\n",
    "# User message template is a template for creating user prompts. It includes placeholders for training data and test input data, guiding the model to learn the rule and apply it to solve the given puzzle.\n",
    "user_message_template = '''Here are the example input and output pairs from which you should learn the underlying rule to later predict the output for the given test input:\n",
    "----------------------------------------\n",
    "{training_data}\n",
    "----------------------------------------\n",
    "Now, solve the following puzzle based on its input grid by applying the rules you have learned from the training data.:\n",
    "----------------------------------------\n",
    "[{{'input': {input_test_data}, 'output': [[]]}}]\n",
    "----------------------------------------\n",
    "What is the output grid? Only provide the output grid in the form as in the example input and output pairs. Do not provide any additional information:'''\n",
    "\n",
    "def preprocess(task, train_mode=True):\n",
    "    \"\"\"\n",
    "    Preprocess a single ARC task to create the prompt and solution for the model.\n",
    "\n",
    "    This function formats the system and user messages using a predefined template and the task's training and test data.\n",
    "    If in training mode, it also includes the assistant's message with the expected output.\n",
    "\n",
    "    Parameters:\n",
    "    task (dict): The ARC task data containing training and test examples.\n",
    "    train_mode (bool): If True, includes the assistant's message with the expected output for training purposes.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary containing the formatted text prompt, the solution, and the file name.\n",
    "    \"\"\"\n",
    "    # System message\n",
    "    system_message = {\"role\": \"system\", \"content\": system_prompt}\n",
    "\n",
    "    # Extract training data and input grid from the task\n",
    "    training_data = task['train']\n",
    "    input_test_data = task['test'][0]['input']\n",
    "    output_test_data = task['test'][0]['output']\n",
    "\n",
    "    # Format the user message with training data and input test data\n",
    "    user_message_content = user_message_template.format(training_data=training_data, input_test_data=input_test_data)\n",
    "    user_message = {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": user_message_content\n",
    "    }\n",
    "\n",
    "    # Include the assistant message with the expected output if in training mode\n",
    "    if train_mode:\n",
    "        assistant_message = {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": str(output_test_data)\n",
    "        }\n",
    "\n",
    "        # Combine system, user, and assistant messages\n",
    "        messages = [system_message, user_message, assistant_message]\n",
    "    else:\n",
    "        messages = [system_message, user_message]\n",
    "    # Convert messages using the chat template for use with the instruction finetuned version of Llama\n",
    "    messages = tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "    return {\"text\": messages, \"solution\": output_test_data, \"file_name\": task['file_name']}\n",
    "\n",
    "# Convert the loaded data to a Huggingface Dataset object\n",
    "dataset = Dataset.from_pandas(df)\n",
    "dataset = dataset.shuffle(seed=42)\n",
    "# Split dataset into training and testing\n",
    "dataset = dataset.train_test_split(test_size=0.2)\n",
    "\n",
    "# Use the map method to apply the preprocess function\n",
    "dataset = dataset.map(preprocess, batched=False, remove_columns=dataset[\"train\"].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "240b8e5e-e28d-4b6e-b50b-273b5b21cb0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "You are a puzzle solving wizard. You are given a puzzle from the abstraction and reasoning corpus developed by Francois Chollet.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "Here are the example input and output pairs from which you should learn the underlying rule to later predict the output for the given test input:\n",
      "----------------------------------------\n",
      "[{'input': [[3, 3, 0, 9, 0, 0], [3, 3, 0, 9, 0, 0], [0, 0, 0, 9, 0, 0], [9, 9, 9, 9, 0, 0], [0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0]], 'output': [[3, 3, 0, 9, 0, 0], [3, 3, 0, 9, 0, 0], [0, 0, 0, 9, 0, 0], [9, 9, 9, 9, 0, 0], [0, 0, 0, 0, 3, 0], [0, 0, 0, 0, 0, 3]]}, {'input': [[0, 0, 8, 0, 6, 0, 8, 0], [0, 0, 8, 0, 0, 0, 8, 0], [0, 0, 8, 8, 8, 8, 8, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0]], 'output': [[0, 0, 8, 0, 6, 0, 8, 0], [0, 0, 8, 0, 0, 0, 8, 0], [0, 0, 8, 8, 8, 8, 8, 0], [0, 6, 0, 0, 0, 0, 0, 6], [6, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0]]}, {'input': [[0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 4, 4, 4, 4, 4, 4, 0, 0], [0, 4, 0, 0, 0, 0, 4, 0, 0], [0, 4, 0, 2, 2, 0, 4, 0, 0], [0, 4, 0, 2, 2, 0, 4, 0, 0]], 'output': [[0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 2], [2, 0, 0, 0, 0, 0, 0, 2, 0], [0, 4, 4, 4, 4, 4, 4, 0, 0], [0, 4, 0, 0, 0, 0, 4, 0, 0], [0, 4, 0, 2, 2, 0, 4, 0, 0], [0, 4, 0, 2, 2, 0, 4, 0, 0]]}, {'input': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [5, 5, 5, 5, 5, 5, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0], [4, 4, 4, 4, 0, 5, 0, 0, 0, 0, 0, 0], [4, 4, 4, 4, 0, 5, 0, 0, 0, 0, 0, 0], [4, 4, 4, 4, 0, 5, 0, 0, 0, 0, 0, 0], [4, 4, 4, 4, 0, 5, 0, 0, 0, 0, 0, 0], [4, 4, 4, 4, 0, 5, 0, 0, 0, 0, 0, 0]], 'output': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0], [5, 5, 5, 5, 5, 5, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0], [4, 4, 4, 4, 0, 5, 0, 0, 0, 0, 0, 0], [4, 4, 4, 4, 0, 5, 0, 0, 0, 0, 0, 0], [4, 4, 4, 4, 0, 5, 0, 0, 0, 0, 0, 0], [4, 4, 4, 4, 0, 5, 0, 0, 0, 0, 0, 0], [4, 4, 4, 4, 0, 5, 0, 0, 0, 0, 0, 0]]}]\n",
      "----------------------------------------\n",
      "Now, solve the following puzzle based on its input grid by applying the rules you have learned from the training data.:\n",
      "----------------------------------------\n",
      "[{'input': [[0, 0, 0, 0, 3, 0, 4, 4, 0, 3, 0, 0], [0, 0, 0, 0, 3, 0, 4, 4, 0, 3, 0, 0], [0, 0, 0, 0, 3, 0, 4, 4, 0, 3, 0, 0], [0, 0, 0, 0, 3, 0, 0, 0, 0, 3, 0, 0], [0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'output': [[]]}]\n",
      "----------------------------------------\n",
      "What is the output grid? Only provide the output grid in the form as in the example input and output pairs. Do not provide any additional information:<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "{'output': [[0, 0, 0, 0, 3, 0, 4, 4, 0, 3, 0, 0], [0, 0, 0, 0, 3, 0, 4, 4, 0, 3, 0, 0], [0, 0, 0, 0, 3, 0, 4, 4, 0, 3, 0, 0], [0, 0, 0, 0, 3, 0, 0, 0, 0, 3, 0, 0], [0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 0, 0], [0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 4, 0], [0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 4], [0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "# Check sample\n",
    "print(dataset['train'][0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "907597c4-2d32-44a6-87b4-4e28545f47bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 320/320 [00:00<00:00, 432.59 examples/s]\n",
      "Map: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 80/80 [00:00<00:00, 465.00 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA18AAAIjCAYAAAD80aFnAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy80BEi2AAAACXBIWXMAAA9hAAAPYQGoP6dpAABHd0lEQVR4nO3deVxWZf7/8fctuyIgLoAbbrgvmaUxkblguIzVaOMyVupotmiZS9PY5pJGWZlWpk2LZJtlqWWl5e7kVy3NJVNRzDUBGwsQU1C4fn/44P51Cyrc4nUDvp6Px/0Y7+tc55zPuc+573jPOec6DmOMEQAAAADgiirn6QIAAAAA4GpA+AIAAAAACwhfAAAAAGAB4QsAAAAALCB8AQAAAIAFhC8AAAAAsIDwBQAAAAAWEL4AAAAAwALCFwAAAABYQPgCUKZNmDBBDofDyro6dOigDh06ON+vXr1aDodDn3zyiZX1Dxo0SHXq1LGyLndlZmZq6NChCg8Pl8Ph0MMPP+zpkoqd7f1+KUuXLtU111wjf39/ORwOpaWlFdgvISFBDodDBw4csFrflVCUbalTp44GDRp0xWsCAInwBaAUyfuDKu/l7++v6tWrKy4uTi+//LJOnDhRLOs5evSoJkyYoK1btxbL8opTSa6tMJ555hklJCTo/vvv17vvvqu77rrrgn3r1Kmjv/71rxarK5oPPvhA06dP93QZF3X8+HH16dNHAQEBmjlzpt59911VqFDB02UVys6dOzVhwoQyEQYBII+3pwsAgKKaNGmS6tatqzNnziglJUWrV6/Www8/rGnTpunzzz9Xy5YtnX2feOIJ/fvf/y7S8o8ePaqJEyeqTp06uuaaawo93zfffFOk9bjjYrW98cYbys3NveI1XI6VK1fqhhtu0Pjx4z1dymX74IMPtGPHjhJ99u7777/XiRMn9PTTTys2Nvaife+66y7169dPfn5+lqq7uJ07d2rixInq0KFDkc/olrRtAYA8hC8ApU63bt103XXXOd+PGzdOK1eu1F//+lfdeuut2rVrlwICAiRJ3t7e8va+sj91f/zxh8qXLy9fX98rup5L8fHx8ej6C+PYsWNq2rSpp8u4ahw7dkySFBIScsm+Xl5e8vLyusIV2VGWtgVA2cJlhwDKhE6dOunJJ5/UwYMH9d577znbC7rna9myZYqJiVFISIgCAwPVqFEjPfbYY5LO3a9z/fXXS5IGDx7svMQxISFB0rn7upo3b67Nmzerffv2Kl++vHPe8+/5ypOTk6PHHntM4eHhqlChgm699VYdPnzYpc+F7jv58zIvVVtB93ydPHlSY8aMUa1ateTn56dGjRrphRdekDHGpZ/D4dCIESO0aNEiNW/eXH5+fmrWrJmWLl1a8Ad+nmPHjmnIkCEKCwuTv7+/WrVqpXfeecc5Pe8+qP379+vLL7901l4cl5S99957atOmjQICAhQaGqp+/frl+3zz9tvOnTvVsWNHlS9fXjVq1NDUqVPzLe/gwYO69dZbVaFCBVWrVk2jRo3S119/LYfDodWrVzuX9+WXX+rgwYPObTn/s8/NzdWUKVNUs2ZN+fv7q3PnzkpKSnLps3fvXvXu3Vvh4eHy9/dXzZo11a9fP6Wnp19yu+fPn+/c7ipVqujOO+/UL7/84rLNAwcOlCRdf/31cjgcF723qaD7pPIu/fz222/Vtm1b+fv7q169epo7d26B865du1b33nuvKleurKCgIN199936/fffXfo6HA5NmDAh3/r//B1ISEjQ3//+d0lSx44dnZ9x3ud/KQVtizFGkydPVs2aNVW+fHl17NhRP/30U755z5w5o4kTJyoqKkr+/v6qXLmyYmJitGzZskKtGwAuhjNfAMqMu+66S4899pi++eYb3XPPPQX2+emnn/TXv/5VLVu21KRJk+Tn56ekpCStW7dOktSkSRNNmjRJTz31lIYNG6abbrpJkvSXv/zFuYzjx4+rW7du6tevn+68806FhYVdtK4pU6bI4XDo0Ucf1bFjxzR9+nTFxsZq69atzjN0hVGY2v7MGKNbb71Vq1at0pAhQ3TNNdfo66+/1iOPPKJffvlFL730kkv/b7/9VgsWLNADDzygihUr6uWXX1bv3r116NAhVa5c+YJ1nTp1Sh06dFBSUpJGjBihunXrav78+Ro0aJDS0tI0cuRINWnSRO+++65GjRqlmjVrasyYMZKkqlWrFnr7CzJlyhQ9+eST6tOnj4YOHapff/1Vr7zyitq3b68tW7a4nPH5/fff1bVrV/Xq1Ut9+vTRJ598okcffVQtWrRQt27dJJ0Lq506dVJycrJGjhyp8PBwffDBB1q1apXLeh9//HGlp6fryJEjzs8xMDDQpc+zzz6rcuXKaezYsUpPT9fUqVM1YMAAbdy4UZKUnZ2tuLg4ZWVl6cEHH1R4eLh++eUXffHFF0pLS1NwcPAFtzshIUGDBw/W9ddfr/j4eKWmpmrGjBlat26dc7sff/xxNWrUSP/5z3+cl+rWr1+/yJ9xUlKS7rjjDg0ZMkQDBw7U22+/rUGDBqlNmzZq1qyZS98RI0YoJCREEyZMUGJiombNmqWDBw86w3dhtW/fXg899JBefvllPfbYY2rSpIkkOf/XHU899ZQmT56s7t27q3v37vrhhx90yy23KDs726XfhAkTFB8fr6FDh6pt27bKyMjQpk2b9MMPP6hLly5urx8AJEkGAEqJOXPmGEnm+++/v2Cf4OBg07p1a+f78ePHmz//1L300ktGkvn1118vuIzvv//eSDJz5szJN+3mm282kszs2bMLnHbzzTc7369atcpIMjVq1DAZGRnO9o8//thIMjNmzHC2RUZGmoEDB15ymRerbeDAgSYyMtL5ftGiRUaSmTx5sku/O+64wzgcDpOUlORsk2R8fX1d2rZt22YkmVdeeSXfuv5s+vTpRpJ57733nG3Z2dkmOjraBAYGumx7ZGSk6dGjx0WXV9i+Bw4cMF5eXmbKlCku7T/++KPx9vZ2ac/bb3PnznW2ZWVlmfDwcNO7d29n24svvmgkmUWLFjnbTp06ZRo3bmwkmVWrVjnbe/To4fJ558nb702aNDFZWVnO9hkzZhhJ5scffzTGGLNlyxYjycyfP//SH8afZGdnm2rVqpnmzZubU6dOOdu/+OILI8k89dRTzrbCfGfO77t//35nW2RkpJFk1q5d62w7duyY8fPzM2PGjMk3b5s2bUx2drazferUqUaS+eyzz5xtksz48ePzrf/878D8+fPzfeaFdf62HDt2zPj6+poePXqY3NxcZ7/HHnvMSHJZb6tWrQp9jAJAUXHZIYAyJTAw8KKjHuadCfnss8/cHpzCz89PgwcPLnT/u+++WxUrVnS+v+OOOxQREaGvvvrKrfUX1ldffSUvLy899NBDLu1jxoyRMUZLlixxaY+NjXU5M9KyZUsFBQXp559/vuR6wsPD1b9/f2ebj4+PHnroIWVmZmrNmjXFsDX5LViwQLm5uerTp4/+97//OV/h4eGKiorKd7YqMDBQd955p/O9r6+v2rZt67J9S5cuVY0aNXTrrbc62/z9/S94JvViBg8e7HIfYN6Zyrz15Z3Z+vrrr/XHH38UermbNm3SsWPH9MADD8jf39/Z3qNHDzVu3FhffvllkWu9mKZNmzprl86drWzUqFGBx8WwYcNc7j28//775e3tfcWP9UtZvny5srOz9eCDD7qcgStosJSQkBD99NNP2rt3r8UKAVwtCF8AypTMzEyXoHO+vn376sYbb9TQoUMVFhamfv366eOPPy5SEKtRo0aRBteIiopyee9wONSgQYMrPoT2wYMHVb169XyfR96lWwcPHnRpr127dr5lVKpUKd89OwWtJyoqSuXKuf4n5ULrKS579+6VMUZRUVGqWrWqy2vXrl3OwSby1KxZM9+lb+dv38GDB1W/fv18/Ro0aFDk+s7/PCtVqiRJzvXVrVtXo0eP1ptvvqkqVaooLi5OM2fOvOT9XnmfZ6NGjfJNa9y4cbF/3kU5Ls4/1gMDAxUREeHx4eLzPpPz66tatapzv+SZNGmS0tLS1LBhQ7Vo0UKPPPKItm/fbq1WAGUb4QtAmXHkyBGlp6df9A/lgIAArV27VsuXL9ddd92l7du3q2/fvurSpYtycnIKtZ6i3KdVWBe6H6awNRWHC40OZ84bnKOkyM3NlcPh0NKlS7Vs2bJ8r9dff92lv+3tK8z6XnzxRW3fvl2PPfaYTp06pYceekjNmjXTkSNHrkhN7rD1udk81i+mffv22rdvn95++201b95cb775pq699lq9+eabni4NQBlA+AJQZrz77ruSpLi4uIv2K1eunDp37qxp06Zp586dmjJlilauXOm8TK0oAwMUxvmXLxljlJSU5DI6XqVKlZSWlpZv3vPPYhSltsjISB09ejTfZZi7d+92Ti8OkZGR2rt3b76zh8W9nvPVr19fxhjVrVtXsbGx+V433HBDkZcZGRmpffv25QsW549SKBXfcdKiRQs98cQTWrt2rf773//ql19+0ezZsy9aoyQlJibmm5aYmHjFPu/COP9Yz8zMVHJy8iWP9ezsbCUnJ7u0Fef3MO8zOb++X3/9tcAzeKGhoRo8eLA+/PBDHT58WC1btixwhEYAKCrCF4AyYeXKlXr66adVt25dDRgw4IL9fvvtt3xteQ8rzsrKkiRVqFBBkgoMQ+6YO3euSwD65JNPlJyc7BxhTzoXJDZs2OAy8toXX3yRb8j0otTWvXt35eTk6NVXX3Vpf+mll+RwOFzWfzm6d++ulJQUffTRR862s2fP6pVXXlFgYKBuvvnmYlnP+Xr16iUvLy9NnDgxX1gyxuj48eNFXmZcXJx++eUXff75586206dP64033sjXt0KFCoUaEv5CMjIydPbsWZe2Fi1aqFy5cs5jsSDXXXedqlWrptmzZ7v0W7JkiXbt2qUePXq4XdPl+s9//qMzZ84438+aNUtnz57Nd6yvXbs233znn/kqzu9hbGysfHx89Morr7gcK9OnT8/X9/zjJjAwUA0aNLjoPgGAwmKoeQClzpIlS7R7926dPXtWqampWrlypZYtW6bIyEh9/vnnLoMQnG/SpElau3atevToocjISB07dkyvvfaaatasqZiYGEnn/jgMCQnR7NmzVbFiRVWoUEHt2rVT3bp13ao3NDRUMTExGjx4sFJTUzV9+nQ1aNDAZRCHoUOH6pNPPlHXrl3Vp08f7du3T++9916+ocGLUlvPnj3VsWNHPf744zpw4IBatWqlb775Rp999pkefvhht4YdL8iwYcP0+uuva9CgQdq8ebPq1KmjTz75ROvWrdP06dMveg/epSQlJWny5Mn52lu3bq0ePXpo8uTJGjdunA4cOKDbb79dFStW1P79+7Vw4UINGzZMY8eOLdL67r33Xr366qvq37+/Ro4cqYiICL3//vvOY+rPZ2PatGmjjz76SKNHj9b111+vwMBA9ezZs9DrWrlypUaMGKG///3vatiwoc6ePat3331XXl5e6t279wXn8/Hx0XPPPafBgwfr5ptvVv/+/Z1DzdepU0ejRo0q0jYXp+zsbHXu3Fl9+vRRYmKiXnvtNcXExLgMYDJ06FDdd9996t27t7p06aJt27bp66+/VpUqVVyWdc0118jLy0vPPfec0tPT5efnp06dOqlatWpFrqtq1aoaO3as4uPj9de//lXdu3fXli1btGTJknzrbdq0qTp06KA2bdooNDRUmzZt0ieffKIRI0a496EAwJ95ZpBFACi6vOGj816+vr4mPDzcdOnSxcyYMcNlSPM85w81v2LFCnPbbbeZ6tWrG19fX1O9enXTv39/s2fPHpf5PvvsM9O0aVPj7e3tMrT7zTffbJo1a1ZgfRcaav7DDz8048aNM9WqVTMBAQGmR48e5uDBg/nmf/HFF02NGjWMn5+fufHGG82mTZvyLfNitZ0/1Lwxxpw4ccKMGjXKVK9e3fj4+JioqCjz/PPPuwy3bcy54b+HDx+er6YLDYF/vtTUVDN48GBTpUoV4+vra1q0aFHgcPhFHWr+z/v7z68hQ4Y4+3366acmJibGVKhQwVSoUME0btzYDB8+3CQmJjr7XGi/FfSZ/fzzz6ZHjx4mICDAVK1a1YwZM8Z8+umnRpLZsGGDs19mZqb5xz/+YUJCQowk53Ly9vv5Q8jv37/fZX/9/PPP5p///KepX7++8ff3N6GhoaZjx45m+fLlhfp8PvroI9O6dWvj5+dnQkNDzYABA8yRI0dc+hTHUPMF7a/zj8u8edesWWOGDRtmKlWqZAIDA82AAQPM8ePHXebNyckxjz76qKlSpYopX768iYuLM0lJSQUea2+88YapV6+e8fLyKtKw8wVtS05Ojpk4caKJiIgwAQEBpkOHDmbHjh351jt58mTTtm1bExISYgICAkzjxo3NlClTXIbQBwB3OYwpoXdSAwBQQkyfPl2jRo3SkSNHVKNGDU+XU+LkPfT5+++/13XXXefpcgCgxOKeLwAA/uTUqVMu70+fPq3XX39dUVFRBC8AwGXhni8AAP6kV69eql27tq655hqlp6frvffe0+7du/X+++97urSrXmZmpjIzMy/ap2rVqhccHh8API3wBQDAn8TFxenNN9/U+++/r5ycHDVt2lTz5s1T3759PV3aVe+FF17QxIkTL9pn//79LkPbA0BJwj1fAACgVPj555/1888/X7RPTEzMRUc8BQBPInwBAAAAgAUMuAEAAAAAFpT5e75yc3N19OhRVaxY0eXhmAAAAACuLsYYnThxQtWrV1e5cvbPQ5X58HX06FHVqlXL02UAAAAAKCEOHz6smjVrWl9vmQ9fFStWlHTuAw4KCvJwNQAAAAA8JSMjQ7Vq1XJmBNvKfPjKu9QwKCiI8AUAAADAY7cjMeAGAAAAAFhA+AIAAAAACwhfAAAAAGAB4QsAAAAALCB8AQAAAIAFhC8AAAAAsIDwBQAAAAAWEL4AAAAAwALCFwAAAABYQPgCAAAAAAsIXwAAAABgAeELAAAAACwgfAEAAACABYQvAAAAALCA8AUAAAAAFhC+AAAAAMACwhcAAAAAWED4AgAAAAALCF8AAAAAYIG3pwtA2dKzp/vzLl5cfHUAAAAAJQ1nvgAAAADAAsIXAAAAAFhA+AIAAAAACwhfAAAAAGAB4QsAAAAALCB8AQAAAIAFhC8AAAAAsIDwBQAAAAAWEL4AAAAAwALCFwAAAABYQPgCAAAAAAsIXwAAAABgAeELAAAAACwgfAEAAACABYQvAAAAALCA8AUAAAAAFhC+AAAAAMACwhcAAAAAWED4AgAAAAALCF8AAAAAYAHhCwAAAAAsIHwBAAAAgAWELwAAAACwgPAFAAAAABYQvgAAAADAAsIXAAAAAFhA+AIAAAAACwhfAAAAAGAB4QsAAAAALCB8AQAAAIAFhC8AAAAAsIDwBQAAAAAWEL4AAAAAwALCFwAAAABYQPgCAAAAAAsIXwAAAABgAeELAAAAACwgfAEAAACABd6eLuBq07One/MtXly8dQAAAACwizNfAAAAAGAB4QsAAAAALCB8AQAAAIAFHg1fEyZMkMPhcHk1btzYOf306dMaPny4KleurMDAQPXu3VupqakerBgAAAAA3OPxM1/NmjVTcnKy8/Xtt986p40aNUqLFy/W/PnztWbNGh09elS9evXyYLUAAAAA4B6Pj3bo7e2t8PDwfO3p6el666239MEHH6hTp06SpDlz5qhJkybasGGDbrjhBtulAgAAAIDbPH7ma+/evapevbrq1aunAQMG6NChQ5KkzZs368yZM4qNjXX2bdy4sWrXrq3169dfcHlZWVnKyMhweQEAAACAp3n0zFe7du2UkJCgRo0aKTk5WRMnTtRNN92kHTt2KCUlRb6+vgoJCXGZJywsTCkpKRdcZnx8vCZOnHiFKy89eK4YAAAAUDJ4NHx169bN+e+WLVuqXbt2ioyM1Mcff6yAgAC3ljlu3DiNHj3a+T4jI0O1atW67FoBAAAA4HJ4/LLDPwsJCVHDhg2VlJSk8PBwZWdnKy0tzaVPampqgfeI5fHz81NQUJDLCwAAAAA8rUSFr8zMTO3bt08RERFq06aNfHx8tGLFCuf0xMREHTp0SNHR0R6sEgAAAACKzqOXHY4dO1Y9e/ZUZGSkjh49qvHjx8vLy0v9+/dXcHCwhgwZotGjRys0NFRBQUF68MEHFR0dzUiHAAAAAEodj4avI0eOqH///jp+/LiqVq2qmJgYbdiwQVWrVpUkvfTSSypXrpx69+6trKwsxcXF6bXXXvNkyQAAAADgFo+Gr3nz5l10ur+/v2bOnKmZM2daqggAAAAArowSdc8XAAAAAJRVhC8AAAAAsIDwBQAAAAAWEL4AAAAAwALCFwAAAABYQPgCAAAAAAsIXwAAAABgAeELAAAAACzw6EOWUXg9e3q6AgAAAACXgzNfAAAAAGAB4QsAAAAALCB8AQAAAIAFhC8AAAAAsIDwBQAAAAAWEL4AAAAAwALCFwAAAABYQPgCAAAAAAsIXwAAAABgAeELAAAAACwgfAEAAACABYQvAAAAALCA8AUAAAAAFhC+AAAAAMACwhcAAAAAWED4AgAAAAALCF8AAAAAYAHhCwAAAAAsIHwBAAAAgAWELwAAAACwgPAFAAAAABYQvgAAAADAAsIXAAAAAFhA+AIAAAAACwhfAAAAAGAB4QsAAAAALCB8AQAAAIAFhC8AAAAAsIDwBQAAAAAWEL4AAAAAwALCFwAAAABYQPgCAAAAAAsIXwAAAABgAeELAAAAACwgfAEAAACABYQvAAAAALCA8AUAAAAAFhC+AAAAAMACwhcAAAAAWED4AgAAAAALCF8AAAAAYAHhCwAAAAAsIHwBAAAAgAWELwAAAACwgPAFAAAAABYQvgAAAADAAsIXAAAAAFhA+AIAAAAACwhfAAAAAGAB4QsAAAAALCB8AQAAAIAFhC8AAAAAsIDwBQAAAAAWEL4AAAAAwALCFwAAAABYQPgCAAAAAAsIXwAAAABgAeELAAAAACwgfAEAAACABSUmfD377LNyOBx6+OGHnW2nT5/W8OHDVblyZQUGBqp3795KTU31XJEAAAAA4KYSEb6+//57vf7662rZsqVL+6hRo7R48WLNnz9fa9as0dGjR9WrVy8PVQkAAAAA7vN4+MrMzNSAAQP0xhtvqFKlSs729PR0vfXWW5o2bZo6deqkNm3aaM6cOfq///s/bdiw4YLLy8rKUkZGhssLAAAAADzN29MFDB8+XD169FBsbKwmT57sbN+8ebPOnDmj2NhYZ1vjxo1Vu3ZtrV+/XjfccEOBy4uPj9fEiROveN1lXc+enq4AAAAAKFs8euZr3rx5+uGHHxQfH59vWkpKinx9fRUSEuLSHhYWppSUlAsuc9y4cUpPT3e+Dh8+XNxlAwAAAECReezM1+HDhzVy5EgtW7ZM/v7+xbZcPz8/+fn5FdvyAAAAAKA4eOzM1+bNm3Xs2DFde+218vb2lre3t9asWaOXX35Z3t7eCgsLU3Z2ttLS0lzmS01NVXh4uGeKBgAAAAA3eezMV+fOnfXjjz+6tA0ePFiNGzfWo48+qlq1asnHx0crVqxQ7969JUmJiYk6dOiQoqOjPVEyAAAAALjNY+GrYsWKat68uUtbhQoVVLlyZWf7kCFDNHr0aIWGhiooKEgPPvigoqOjLzjYBgAAAACUVB4f7fBiXnrpJZUrV069e/dWVlaW4uLi9Nprr3m6LAAAAAAoMocxxni6iCspIyNDwcHBSk9PV1BQkKfLYQj3i1i82NMVAAAAoCzzdDbw+EOWAQAAAOBqQPgCAAAAAAsIXwAAAABgAeELAAAAACwgfAEAAACABYQvAAAAALCA8AUAAAAAFhC+AAAAAMACwhcAAAAAWED4AgAAAAALCF8AAAAAYAHhCwAAAAAsIHwBAAAAgAWELwAAAACwgPAFAAAAABYQvgAAAADAAsIXAAAAAFhA+AIAAAAACwhfAAAAAGAB4QsAAAAALCB8AQAAAIAFhC8AAAAAsIDwBQAAAAAWEL4AAAAAwALCFwAAAABYQPgCAAAAAAsIXwAAAABgAeELAAAAACwgfAEAAACABYQvAAAAALCA8AUAAAAAFhC+AAAAAMACwhcAAAAAWED4AgAAAAALCF8AAAAAYAHhCwAAAAAsIHwBAAAAgAWELwAAAACwgPAFAAAAABYQvgAAAADAAsIXAAAAAFhA+AIAAAAACwhfAAAAAGCBW+Hr559/Lu46AAAAAKBMcyt8NWjQQB07dtR7772n06dPF3dNAAAAAFDmuBW+fvjhB7Vs2VKjR49WeHi47r33Xn333XfFXRsAAAAAlBluha9rrrlGM2bM0NGjR/X2228rOTlZMTExat68uaZNm6Zff/21uOsEAAAAgFLtsgbc8Pb2Vq9evTR//nw999xzSkpK0tixY1WrVi3dfffdSk5OLq46AQAAAKBUu6zwtWnTJj3wwAOKiIjQtGnTNHbsWO3bt0/Lli3T0aNHddtttxVXnQAAAABQqnm7M9O0adM0Z84cJSYmqnv37po7d666d++ucuXOZbm6desqISFBderUKc5aAQAAAKDUcit8zZo1S//85z81aNAgRUREFNinWrVqeuutty6rOAAAAAAoK9wKX3v37r1kH19fXw0cONCdxQMAAABAmePWPV9z5szR/Pnz87XPnz9f77zzzmUXBQAAAABljVvhKz4+XlWqVMnXXq1aNT3zzDOXXRQAAAAAlDVuha9Dhw6pbt26+dojIyN16NChyy4KAAAAAMoat8JXtWrVtH379nzt27ZtU+XKlS+7KAAAAAAoa9wKX/3799dDDz2kVatWKScnRzk5OVq5cqVGjhypfv36FXeNAAAAAFDquTXa4dNPP60DBw6oc+fO8vY+t4jc3Fzdfffd3PMFAAAAAAVwK3z5+vrqo48+0tNPP61t27YpICBALVq0UGRkZHHXBwAAAABlglvhK0/Dhg3VsGHD4qoFAAAAAMost8JXTk6OEhIStGLFCh07dky5ubku01euXFksxQEAAABAWeFW+Bo5cqQSEhLUo0cPNW/eXA6Ho7jrAgAAAIAyxa3wNW/ePH388cfq3r17cdcDAAAAAGWSW0PN+/r6qkGDBsVdCwAAAACUWW6FrzFjxmjGjBkyxhR3PQAAAABQJrl12eG3336rVatWacmSJWrWrJl8fHxcpi9YsKBYigMAAACAssKt8BUSEqK//e1vxV0LAAAAAJRZboWvOXPmFMvKZ82apVmzZunAgQOSpGbNmumpp55St27dJEmnT5/WmDFjNG/ePGVlZSkuLk6vvfaawsLCimX9AAAAAGCLW/d8SdLZs2e1fPlyvf766zpx4oQk6ejRo8rMzCz0MmrWrKlnn31Wmzdv1qZNm9SpUyfddttt+umnnyRJo0aN0uLFizV//nytWbNGR48eVa9evdwtGQAAAAA8xmHcGDXj4MGD6tq1qw4dOqSsrCzt2bNH9erV08iRI5WVlaXZs2e7XVBoaKief/553XHHHapatao++OAD3XHHHZKk3bt3q0mTJlq/fr1uuOGGQi0vIyNDwcHBSk9PV1BQkNt1FZeePT1dQcm1eLGnKwAAAEBZ5uls4NaZr5EjR+q6667T77//roCAAGf73/72N61YscKtQnJycjRv3jydPHlS0dHR2rx5s86cOaPY2Fhnn8aNG6t27dpav379BZeTlZWljIwMlxcAAAAAeJpb93z997//1f/93//J19fXpb1OnTr65ZdfirSsH3/8UdHR0Tp9+rQCAwO1cOFCNW3aVFu3bpWvr69CQkJc+oeFhSklJeWCy4uPj9fEiROLVAMAAAAAXGlunfnKzc1VTk5OvvYjR46oYsWKRVpWo0aNtHXrVm3cuFH333+/Bg4cqJ07d7pTliRp3LhxSk9Pd74OHz7s9rIAAAAAoLi4Fb5uueUWTZ8+3fne4XAoMzNT48ePV/fu3Yu0LF9fXzVo0EBt2rRRfHy8WrVqpRkzZig8PFzZ2dlKS0tz6Z+amqrw8PALLs/Pz09BQUEuLwAAAADwNLfC14svvqh169apadOmOn36tP7xj384Lzl87rnnLqug3NxcZWVlqU2bNvLx8XG5hywxMVGHDh1SdHT0Za0DAAAAAGxz656vmjVratu2bZo3b562b9+uzMxMDRkyRAMGDHAZgONSxo0bp27duql27do6ceKEPvjgA61evVpff/21goODNWTIEI0ePVqhoaEKCgrSgw8+qOjo6EKPdAgAAAAAJYVb4UuSvL29deedd17Wyo8dO6a7775bycnJCg4OVsuWLfX111+rS5cukqSXXnpJ5cqVU+/evV0esgwAAAAApY1bz/maO3fuRafffffdbhdU3Dw9lv/5eM7XhfGcLwAAAFxJns4Gbp35GjlypMv7M2fO6I8//pCvr6/Kly9fosIXAAAAAJQEbg248fvvv7u8MjMzlZiYqJiYGH344YfFXSMAAAAAlHpuha+CREVF6dlnn813VgwAAAAAUIzhSzo3CMfRo0eLc5EAAAAAUCa4dc/X559/7vLeGKPk5GS9+uqruvHGG4ulMAAAAAAoS9wKX7fffrvLe4fDoapVq6pTp0568cUXi6MuAAAAAChT3Apfubm5xV0HAAAAAJRpxXrPFwAAAACgYG6d+Ro9enSh+06bNs2dVQAAAABAmeJW+NqyZYu2bNmiM2fOqFGjRpKkPXv2yMvLS9dee62zn8PhKJ4qAQAAAKCUcyt89ezZUxUrVtQ777yjSpUqSTr34OXBgwfrpptu0pgxY4q1SAAAAAAo7RzGGFPUmWrUqKFvvvlGzZo1c2nfsWOHbrnllhL1rK+MjAwFBwcrPT1dQUFBni5HPXt6uoKSa/FiT1cAAACAsszT2cCtATcyMjL066+/5mv/9ddfdeLEicsuCgAAAADKGrfC19/+9jcNHjxYCxYs0JEjR3TkyBF9+umnGjJkiHr16lXcNQIAAABAqefWPV+zZ8/W2LFj9Y9//ENnzpw5tyBvbw0ZMkTPP/98sRYIAAAAAGWBW/d85Tl58qT27dsnSapfv74qVKhQbIUVF09f13k+7vm6MO75AgAAwJXk6WxwWQ9ZTk5OVnJysqKiolShQgVdRo4DAAAAgDLNrfB1/Phxde7cWQ0bNlT37t2VnJwsSRoyZAjDzAMAAABAAdwKX6NGjZKPj48OHTqk8uXLO9v79u2rpUuXFltxAAAAAFBWuDXgxjfffKOvv/5aNWvWdGmPiorSwYMHi6UwAAAAAChL3DrzdfLkSZczXnl+++03+fn5XXZRAAAAAFDWuBW+brrpJs2dO9f53uFwKDc3V1OnTlXHjh2LrTgAAAAAKCvcuuxw6tSp6ty5szZt2qTs7Gz961//0k8//aTffvtN69atK+4aAQAAAKDUc+vMV/PmzbVnzx7FxMTotttu08mTJ9WrVy9t2bJF9evXL+4aAQAAAKDUK/KZrzNnzqhr166aPXu2Hn/88StREwAAAACUOUU+8+Xj46Pt27dfiVoAAAAAoMxy67LDO++8U2+99VZx1wIAAAAAZZZbA26cPXtWb7/9tpYvX642bdqoQoUKLtOnTZtWLMUBAAAAQFlRpPD1888/q06dOtqxY4euvfZaSdKePXtc+jgcjuKrDgAAAADKiCKFr6ioKCUnJ2vVqlWSpL59++rll19WWFjYFSkOAAAAAMqKIt3zZYxxeb9kyRKdPHmyWAsCAAAAgLLIrQE38pwfxgAAAAAABStS+HI4HPnu6eIeLwAAAAC4tCLd82WM0aBBg+Tn5ydJOn36tO677758ox0uWLCg+CoEAAAAgDKgSOFr4MCBLu/vvPPOYi0GAAAAAMqqIoWvOXPmXKk6AAAAAKBMu6wBNwAAAAAAhUP4AgAAAAALCF8AAAAAYAHhCwAAAAAsIHwBAAAAgAWELwAAAACwgPAFAAAAABYQvgAAAADAAsIXAAAAAFhA+AIAAAAACwhfAAAAAGAB4QsAAAAALCB8AQAAAIAFhC8AAAAAsIDwBQAAAAAWEL4AAAAAwALCFwAAAABYQPgCAAAAAAsIXwAAAABgAeELAAAAACzw9nQBQGnTs6d78y1eXLx1AAAAoHThzBcAAAAAWED4AgAAAAALCF8AAAAAYAHhCwAAAAAsIHwBAAAAgAWELwAAAACwgPAFAAAAABYQvgAAAADAAsIXAAAAAFhA+AIAAAAACwhfAAAAAGCBR8NXfHy8rr/+elWsWFHVqlXT7bffrsTERJc+p0+f1vDhw1W5cmUFBgaqd+/eSk1N9VDFAAAAAOAej4avNWvWaPjw4dqwYYOWLVumM2fO6JZbbtHJkyedfUaNGqXFixdr/vz5WrNmjY4ePapevXp5sGoAAAAAKDpvT6586dKlLu8TEhJUrVo1bd68We3bt1d6erreeustffDBB+rUqZMkac6cOWrSpIk2bNigG264Id8ys7KylJWV5XyfkZFxZTcCAAAAAArBo+HrfOnp6ZKk0NBQSdLmzZt15swZxcbGOvs0btxYtWvX1vr16wsMX/Hx8Zo4caKdglGsevZ0b77Fi4u3DgAAAOBKKDEDbuTm5urhhx/WjTfeqObNm0uSUlJS5Ovrq5CQEJe+YWFhSklJKXA548aNU3p6uvN1+PDhK106AAAAAFxSiTnzNXz4cO3YsUPffvvtZS3Hz89Pfn5+xVQVAAAAABSPEnHma8SIEfriiy+0atUq1axZ09keHh6u7OxspaWlufRPTU1VeHi45SoBAAAAwH0eDV/GGI0YMUILFy7UypUrVbduXZfpbdq0kY+Pj1asWOFsS0xM1KFDhxQdHW27XAAAAABwm0cvOxw+fLg++OADffbZZ6pYsaLzPq7g4GAFBAQoODhYQ4YM0ejRoxUaGqqgoCA9+OCDio6OLnCwDQAAAAAoqTwavmbNmiVJ6tChg0v7nDlzNGjQIEnSSy+9pHLlyql3797KyspSXFycXnvtNcuVAgAAAMDl8Wj4MsZcso+/v79mzpypmTNnWqgIAAAAAK6MEjHgBgAAAACUdYQvAAAAALCA8AUAAAAAFhC+AAAAAMACwhcAAAAAWED4AgAAAAALCF8AAAAAYAHhCwAAAAAsIHwBAAAAgAWELwAAAACwgPAFAAAAABYQvgAAAADAAsIXAAAAAFhA+AIAAAAACwhfAAAAAGAB4QsAAAAALCB8AQAAAIAFhC8AAAAAsIDwBQAAAAAWEL4AAAAAwALCFwAAAABYQPgCAAAAAAsIXwAAAABgAeELAAAAACzw9nQBwOXq2dO9+RYvLt46LqW01AkAAIArgzNfAAAAAGAB4QsAAAAALCB8AQAAAIAFhC8AAAAAsIDwBQAAAAAWEL4AAAAAwALCFwAAAABYQPgCAAAAAAsIXwAAAABgAeELAAAAACwgfAEAAACABYQvAAAAALCA8AUAAAAAFhC+AAAAAMACwhcAAAAAWODt6QIAT+nZ09MVAAAA4GrCmS8AAAAAsIDwBQAAAAAWEL4AAAAAwALCFwAAAABYQPgCAAAAAAsIXwAAAABgAeELAAAAACwgfAEAAACABYQvAAAAALCA8AUAAAAAFhC+AAAAAMACwhcAAAAAWED4AgAAAAALCF8AAAAAYAHhCwAAAAAsIHwBAAAAgAWELwAAAACwgPAFAAAAABYQvgAAAADAAsIXAAAAAFhA+AIAAAAACwhfAAAAAGCBt6cLAHBl9Ozp3nyLFxdvHQAAADiHM18AAAAAYAHhCwAAAAAsIHwBAAAAgAUeDV9r165Vz549Vb16dTkcDi1atMhlujFGTz31lCIiIhQQEKDY2Fjt3bvXM8UCAAAAwGXwaPg6efKkWrVqpZkzZxY4ferUqXr55Zc1e/Zsbdy4URUqVFBcXJxOnz5tuVIAAAAAuDweHe2wW7du6tatW4HTjDGaPn26nnjiCd12222SpLlz5yosLEyLFi1Sv379bJYKAAAAAJelxN7ztX//fqWkpCg2NtbZFhwcrHbt2mn9+vUXnC8rK0sZGRkuLwAAAADwtBL7nK+UlBRJUlhYmEt7WFiYc1pB4uPjNXHixCtaG1CW8XwwAACAK6PEnvly17hx45Senu58HT582NMlAQAAAEDJDV/h4eGSpNTUVJf21NRU57SC+Pn5KSgoyOUFAAAAAJ5WYsNX3bp1FR4erhUrVjjbMjIytHHjRkVHR3uwMgAAAAAoOo/e85WZmamkpCTn+/3792vr1q0KDQ1V7dq19fDDD2vy5MmKiopS3bp19eSTT6p69eq6/fbbPVc0AAAAALjBo+Fr06ZN6tixo/P96NGjJUkDBw5UQkKC/vWvf+nkyZMaNmyY0tLSFBMTo6VLl8rf399TJQMAAACAWzwavjp06CBjzAWnOxwOTZo0SZMmTbJYFQAAAAAUvxJ7zxcAAAAAlCUl9jlfAM5x97lbAAAAKFk48wUAAAAAFhC+AAAAAMACwhcAAAAAWED4AgAAAAALCF8AAAAAYAHhCwAAAAAsIHwBAAAAgAWELwAAAACwgPAFAAAAABYQvgAAAADAAsIXAAAAAFhA+AIAAAAACwhfAAAAAGAB4QsAAAAALCB8AQAAAIAFhC8AAAAAsIDwBQAAAAAWEL4AAAAAwALCFwAAAABYQPgCAAAAAAsIXwAAAABgAeELAAAAACzw9nQBAK5uPXu6N9/ixcVbR0nEZwMAQNnCmS8AAAAAsIDwBQAAAAAWEL4AAAAAwALCFwAAAABYQPgCAAAAAAsIXwAAAABgAeELAAAAACwgfAEAAACABYQvAAAAALCA8AUAAAAAFhC+AAAAAMACwhcAAAAAWED4AgAAAAALCF8AAAAAYAHhCwAAAAAs8PZ0AQCA0q1nT/fmW7y4eOsAAKCk48wXAAAAAFhA+AIAAAAACwhfAAAAAGAB4QsAAAAALCB8AQAAAIAFhC8AAAAAsIDwBQAAAAAW8JwvAMXC3Wc9XQ34bAAAgMSZLwAAAACwgvAFAAAAABYQvgAAAADAAsIXAAAAAFhA+AIAAAAACwhfAAAAAGAB4QsAAAAALOA5XwBKpct5dtbixfbXifzc/Tzd3X8A8uN7CNjFmS8AAAAAsIDwBQAAAAAWEL4AAAAAwALCFwAAAABYQPgCAAAAAAsIXwAAAABgAeELAAAAACzgOV8Arjo8rwtF4Ynjxfaz6ErL+so6Tzy/ECgqvveXhzNfAAAAAGAB4QsAAAAALCB8AQAAAIAFpSJ8zZw5U3Xq1JG/v7/atWun7777ztMlAQAAAECRlPjw9dFHH2n06NEaP368fvjhB7Vq1UpxcXE6duyYp0sDAAAAgEIr8eFr2rRpuueeezR48GA1bdpUs2fPVvny5fX22297ujQAAAAAKLQSPdR8dna2Nm/erHHjxjnbypUrp9jYWK1fv77AebKyspSVleV8n56eLknKyMi4ssUW0pkznq4AQFln++fO9u9aWd8+yf1tdLfW0rK+su5yjjX2IWwp7cdMXiYwxnhk/SU6fP3vf/9TTk6OwsLCXNrDwsK0e/fuAueJj4/XxIkT87XXqlXritQIACVNcLCnK7iyyvr2Sfa3sayv72rAPkRJV9KOmePHjyvYA0WV6PDljnHjxmn06NHO97m5ufrtt99UuXJlORwOSecSb61atXT48GEFBQV5qlR4CPsfHANXN/b/1Y39f3Vj/yM9PV21a9dWaGioR9ZfosNXlSpV5OXlpdTUVJf21NRUhYeHFziPn5+f/Pz8XNpCQkIK7BsUFMQX7yrG/gfHwNWN/X91Y/9f3dj/KFfOM0NflOgBN3x9fdWmTRutWLHC2Zabm6sVK1YoOjrag5UBAAAAQNGU6DNfkjR69GgNHDhQ1113ndq2bavp06fr5MmTGjx4sKdLAwAAAIBCK/Hhq2/fvvr111/11FNPKSUlRddcc42WLl2abxCOovDz89P48ePzXZ6IqwP7HxwDVzf2/9WN/X91Y//D08eAw3hqnEUAAAAAuIqU6Hu+AAAAAKCsIHwBAAAAgAWELwAAAACwgPAFAAAAABZcdeFr5syZqlOnjvz9/dWuXTt99913ni4JbpgwYYIcDofLq3Hjxs7pp0+f1vDhw1W5cmUFBgaqd+/e+R7WfejQIfXo0UPly5dXtWrV9Mgjj+js2bMufVavXq1rr71Wfn5+atCggRISEmxsHs6zdu1a9ezZU9WrV5fD4dCiRYtcphtj9NRTTykiIkIBAQGKjY3V3r17Xfr89ttvGjBggIKCghQSEqIhQ4YoMzPTpc/27dt10003yd/fX7Vq1dLUqVPz1TJ//nw1btxY/v7+atGihb766qti3164utT+HzRoUL7fg65du7r0Yf+XXvHx8br++utVsWJFVatWTbfffrsSExNd+tj8zefvCPsKcwx06NAh3+/Afffd59KHY6B0mjVrllq2bOl8MHZ0dLSWLFninF7qvv/mKjJv3jzj6+tr3n77bfPTTz+Ze+65x4SEhJjU1FRPl4YiGj9+vGnWrJlJTk52vn799Vfn9Pvuu8/UqlXLrFixwmzatMnccMMN5i9/+Ytz+tmzZ03z5s1NbGys2bJli/nqq69MlSpVzLhx45x9fv75Z1O+fHkzevRos3PnTvPKK68YLy8vs3TpUqvbCmO++uor8/jjj5sFCxYYSWbhwoUu05999lkTHBxsFi1aZLZt22ZuvfVWU7duXXPq1Clnn65du5pWrVqZDRs2mP/+97+mQYMGpn///s7p6enpJiwszAwYMMDs2LHDfPjhhyYgIMC8/vrrzj7r1q0zXl5eZurUqWbnzp3miSeeMD4+PubHH3+84p/B1exS+3/gwIGma9euLr8Hv/32m0sf9n/pFRcXZ+bMmWN27Nhhtm7darp3725q165tMjMznX1s/ebzd4RnFOYYuPnmm80999zj8juQnp7unM4xUHp9/vnn5ssvvzR79uwxiYmJ5rHHHjM+Pj5mx44dxpjS9/2/qsJX27ZtzfDhw53vc3JyTPXq1U18fLwHq4I7xo8fb1q1alXgtLS0NOPj42Pmz5/vbNu1a5eRZNavX2+MOffHXLly5UxKSoqzz6xZs0xQUJDJysoyxhjzr3/9yzRr1sxl2X379jVxcXHFvDUoivP/+M7NzTXh4eHm+eefd7alpaUZPz8/8+GHHxpjjNm5c6eRZL7//ntnnyVLlhiHw2F++eUXY4wxr732mqlUqZJz/xtjzKOPPmoaNWrkfN+nTx/To0cPl3ratWtn7r333mLdRlzYhcLXbbfddsF52P9ly7Fjx4wks2bNGmOM3d98/o4oGc4/Bow5F75Gjhx5wXk4BsqWSpUqmTfffLNUfv+vmssOs7OztXnzZsXGxjrbypUrp9jYWK1fv96DlcFde/fuVfXq1VWvXj0NGDBAhw4dkiRt3rxZZ86ccdnXjRs3Vu3atZ37ev369WrRooXLw7rj4uKUkZGhn376ydnnz8vI68PxUrLs379fKSkpLvsqODhY7dq1c9nfISEhuu6665x9YmNjVa5cOW3cuNHZp3379vL19XX2iYuLU2Jion7//XdnH46Jkmn16tWqVq2aGjVqpPvvv1/Hjx93TmP/ly3p6emSpNDQUEn2fvP5O6LkOP8YyPP++++rSpUqat68ucaNG6c//vjDOY1joGzIycnRvHnzdPLkSUVHR5fK77930Ta59Prf//6nnJwclw9eksLCwrR7924PVQV3tWvXTgkJCWrUqJGSk5M1ceJE3XTTTdqxY4dSUlLk6+urkJAQl3nCwsKUkpIiSUpJSSnwWMibdrE+GRkZOnXqlAICAq7Q1qEo8vZXQfvqz/uyWrVqLtO9vb0VGhrq0qdu3br5lpE3rVKlShc8JvKWAc/o2rWrevXqpbp162rfvn167LHH1K1bN61fv15eXl7s/zIkNzdXDz/8sG688UY1b95ckqz95v/+++/8HVECFHQMSNI//vEPRUZGqnr16tq+fbseffRRJSYmasGCBZI4Bkq7H3/8UdHR0Tp9+rQCAwO1cOFCNW3aVFu3bi113/+rJnyhbOnWrZvz3y1btlS7du0UGRmpjz/+mFAEXGX69evn/HeLFi3UsmVL1a9fX6tXr1bnzp09WBmK2/Dhw7Vjxw59++23ni4FHnKhY2DYsGHOf7do0UIRERHq3Lmz9u3bp/r169suE8WsUaNG2rp1q9LT0/XJJ59o4MCBWrNmjafLcstVc9lhlSpV5OXllW/0k9TUVIWHh3uoKhSXkJAQNWzYUElJSQoPD1d2drbS0tJc+vx5X4eHhxd4LORNu1ifoKAgAl4Jkre/LvbdDg8P17Fjx1ymnz17Vr/99luxHBP8hpQs9erVU5UqVZSUlCSJ/V9WjBgxQl988YVWrVqlmjVrOttt/ebzd4TnXegYKEi7du0kyeV3gGOg9PL19VWDBg3Upk0bxcfHq1WrVpoxY0ap/P5fNeHL19dXbdq00YoVK5xtubm5WrFihaKjoz1YGYpDZmam9u3bp4iICLVp00Y+Pj4u+zoxMVGHDh1y7uvo6Gj9+OOPLn+QLVu2TEFBQWratKmzz5+XkdeH46VkqVu3rsLDw132VUZGhjZu3Oiyv9PS0rR582Znn5UrVyo3N9f5H+jo6GitXbtWZ86ccfZZtmyZGjVqpEqVKjn7cEyUfEeOHNHx48cVEREhif1f2hljNGLECC1cuFArV67Md3mord98/o7wnEsdAwXZunWrJLn8DnAMlB25ubnKysoqnd//Ig3PUcrNmzfP+Pn5mYSEBLNz504zbNgwExIS4jL6CUqHMWPGmNWrV5v9+/ebdevWmdjYWFOlShVz7NgxY8y5YUdr165tVq5caTZt2mSio6NNdHS0c/68YUdvueUWs3XrVrN06VJTtWrVAocdfeSRR8yuXbvMzJkzGWreQ06cOGG2bNlitmzZYiSZadOmmS1btpiDBw8aY84NNR8SEmI+++wzs337dnPbbbcVONR869atzcaNG823335roqKiXIYaT0tLM2FhYeauu+4yO3bsMPPmzTPly5fPN9S4t7e3eeGFF8yuXbvM+PHjGWrcgovt/xMnTpixY8ea9evXm/3795vly5eba6+91kRFRZnTp087l8H+L73uv/9+ExwcbFavXu0yjPgff/zh7GPrN5+/IzzjUsdAUlKSmTRpktm0aZPZv3+/+eyzz0y9evVM+/btncvgGCi9/v3vf5s1a9aY/fv3m+3bt5t///vfxuFwmG+++cYYU/q+/1dV+DLGmFdeecXUrl3b+Pr6mrZt25oNGzZ4uiS4oW/fviYiIsL4+vqaGjVqmL59+5qkpCTn9FOnTpkHHnjAVKpUyZQvX9787W9/M8nJyS7LOHDggOnWrZsJCAgwVapUMWPGjDFnzpxx6bNq1SpzzTXXGF9fX1OvXj0zZ84cG5uH86xatcpIyvcaOHCgMebccPNPPvmkCQsLM35+fqZz584mMTHRZRnHjx83/fv3N4GBgSYoKMgMHjzYnDhxwqXPtm3bTExMjPHz8zM1atQwzz77bL5aPv74Y9OwYUPj6+trmjVrZr788ssrtt0452L7/48//jC33HKLqVq1qvHx8TGRkZHmnnvuyfcfQ/Z/6VXQvpfk8nts8zefvyPsu9QxcOjQIdO+fXsTGhpq/Pz8TIMGDcwjjzzi8pwvYzgGSqt//vOfJjIy0vj6+pqqVauazp07O4OXMaXv++8wxpiinSsDAAAAABTVVXPPFwAAAAB4EuELAAAAACwgfAEAAACABYQvAAAAALCA8AUAAAAAFhC+AAAAAMACwhcAAAAAWED4AgAAAAALCF8AAI8aNGiQbr/99mJfbkpKirp06aIKFSooJCTE6rqvhDp16mj69OkX7eNwOLRo0SIr9QAAio7wBQBXgZIQMg4cOCCHw6GtW7daWd9LL72k5ORkbd26VXv27Cmwz4wZM5SQkGClnj9LSEi4YCC8kO+//17Dhg27MgUBAKzw9nQBAABcCfv27VObNm0UFRV1wT7BwcEWK7o8VatW9XQJAIDLxJkvAIB27Nihbt26KTAwUGFhYbrrrrv0v//9zzm9Q4cOeuihh/Svf/1LoaGhCg8P14QJE1yWsXv3bsXExMjf319NmzbV8uXLXS6Dq1u3riSpdevWcjgc6tChg8v8L7zwgiIiIlS5cmUNHz5cZ86cuWjNs2bNUv369eXr66tGjRrp3XffdU6rU6eOPv30U82dO1cOh0ODBg0qcBnnnxEszHY6HA7NmjVL3bp1U0BAgOrVq6dPPvnEOX316tVyOBxKS0tztm3dulUOh0MHDhzQ6tWrNXjwYKWnp8vhcMjhcORbR0HOv+xw7969at++vfPzXrZsmUv/7OxsjRgxQhEREfL391dkZKTi4+MvuR4AwJVD+AKAq1xaWpo6deqk1q1ba9OmTVq6dKlSU1PVp08fl37vvPOOKlSooI0bN2rq1KmaNGmS8w/+nJwc3X777Spfvrw2btyo//znP3r88cdd5v/uu+8kScuXL1dycrIWLFjgnLZq1Srt27dPq1at0jvvvKOEhISLXg64cOFCjRw5UmPGjNGOHTt07733avDgwVq1apWkc5fode3aVX369FFycrJmzJhR6M/jYtuZ58knn1Tv3r21bds2DRgwQP369dOuXbsKtfy//OUvmj59uoKCgpScnKzk5GSNHTu20PVJUm5urnr16iVfX19t3LhRs2fP1qOPPurS5+WXX9bnn3+ujz/+WImJiXr//fdVp06dIq0HAFC8uOwQAK5yr776qlq3bq1nnnnG2fb222+rVq1a2rNnjxo2bChJatmypcaPHy9JioqK0quvvqoVK1aoS5cuWrZsmfbt26fVq1crPDxckjRlyhR16dLFucy8y+YqV67s7JOnUqVKevXVV+Xl5aXGjRurR48eWrFihe65554Ca37hhRc0aNAgPfDAA5Kk0aNHa8OGDXrhhRfUsWNHVa1aVX5+fgoICMi3rku52Hbm+fvf/66hQ4dKkp5++mktW7ZMr7zyil577bVLLt/X11fBwcFyOBxFri3P8uXLtXv3bn399deqXr26JOmZZ55Rt27dnH0OHTqkqKgoxcTEyOFwKDIy0q11AQCKD2e+AOAqt23bNq1atUqBgYHOV+PGjSWdu28qT8uWLV3mi4iI0LFjxyRJiYmJqlWrlkuYaNu2baFraNasmby8vApcdkF27dqlG2+80aXtxhtvLPTZp4u52HbmiY6Ozve+ONZdWLt27VKtWrWcwaugmgYNGqStW7eqUaNGeuihh/TNN99Yqw8AUDDOfAHAVS4zM1M9e/bUc889l29aRESE898+Pj4u0xwOh3Jzc4ulhiu5bNu1lCt37v/XNMY42y51/9qVcO2112r//v1asmSJli9frj59+ig2Ntbl/jQAgF2c+QKAq9y1116rn376SXXq1FGDBg1cXhUqVCjUMho1aqTDhw8rNTXV2fb999+79PH19ZV07v6wy9WkSROtW7fOpW3dunVq2rTpZS+7MDZs2JDvfZMmTST9/8srk5OTndPPH17f19f3sj6HJk2a6PDhwy7rOL8mSQoKClLfvn31xhtv6KOPPtKnn36q3377ze31AgAuD2e+AOAqkZ6eni8E5I0s+MYbb6h///7OUf6SkpI0b948vfnmmy6XA15Ily5dVL9+fQ0cOFBTp07ViRMn9MQTT0g6d+ZIkqpVq6aAgAAtXbpUNWvWlL+/v9tDvT/yyCPq06ePWrdurdjYWC1evFgLFizQ8uXL3VpeUc2fP1/XXXedYmJi9P777+u7777TW2+9JUlq0KCBatWqpQkTJmjKlCnas2ePXnzxRZf569Spo8zMTK1YsUKtWrVS+fLlVb58+UKvPzY2Vg0bNtTAgQP1/PPPKyMjI98AJ9OmTVNERIRat26tcuXKaf78+QoPDy/y88UAAMWHM18AcJVYvXq1Wrdu7fKaOHGiqlevrnXr1iknJ0e33HKLWrRooYcfflghISHOS+guxcvLS4sWLVJmZqauv/56DR061BkG/P39JUne3t56+eWX9frrr6t69eq67bbb3N6W22+/XTNmzNALL7ygZs2a6fXXX9ecOXPyDV9/pUycOFHz5s1Ty5YtNXfuXH344YfOs24+Pj768MMPtXv3brVs2VLPPfecJk+e7DL/X/7yF913333q27evqlatqqlTpxZp/eXKldPChQt16tQptW3bVkOHDtWUKVNc+lSsWFFTp07Vddddp+uvv14HDhzQV199Veh9CgAofg7z54vSAQAoJuvWrVNMTIySkpJUv359T5dTbBwOhxYuXOjyfDAAAAqDyw4BAMVi4cKFCgwMVFRUlJKSkjRy5EjdeOONZSp4AQBwOQhfAIBiceLECT366KM6dOiQqlSpotjY2Hz3OqFg//3vf12e0XW+zMxMi9UAAK4ULjsEAMDDTp06pV9++eWC0xs0aGCxGgDAlUL4AgAAAAALGPIIAAAAACwgfAEAAACABYQvAAAAALCA8AUAAAAAFhC+AAAAAMACwhcAAAAAWED4AgAAAAAL/h/GoMoOSXTOcAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tokenize the dataset and store tokenized samples\n",
    "data = dataset.map(lambda samples: tokenizer(samples['text']), batched=False)\n",
    "\n",
    "def plot_data_lengths(tokenized_train_dataset, tokenized_val_dataset):\n",
    "    \"\"\"\n",
    "    Plot the distribution of token lengths in the training and validation datasets.\n",
    "\n",
    "    This function calculates the length of tokenized input texts in both the training and \n",
    "    validation datasets, combines the lengths, and plots a histogram to visualize their distribution.\n",
    "\n",
    "    Parameters:\n",
    "    tokenized_train_dataset (Dataset): The tokenized training dataset.\n",
    "    tokenized_val_dataset (Dataset): The tokenized validation dataset.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Calculate the lengths of tokenized texts in the training dataset\n",
    "    lengths = [len(x['text']) for x in tokenized_train_dataset]\n",
    "    # Add the lengths of tokenized texts in the validation dataset\n",
    "    lengths += [len(x['text']) for x in tokenized_val_dataset]\n",
    "    \n",
    "    # Print the total number of lengths calculated\n",
    "    print(len(lengths))\n",
    "\n",
    "    # Plotting the histogram of token lengths\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(lengths, bins=50, alpha=0.7, color='blue')\n",
    "    plt.xlabel('Length of input_ids')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Distribution of Lengths of input_ids')\n",
    "    # Uncomment the line below to set x-axis limits, if needed\n",
    "    # plt.xlim([0, 1500])\n",
    "    plt.show()\n",
    "\n",
    "# Plot the distribution of token lengths in the training and validation datasets\n",
    "plot_data_lengths(data['train'], data['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad1a802c-512a-45c3-b2f3-bba167db345d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 320/320 [00:00<00:00, 521.31 examples/s]\n",
      "Filter: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 80/80 [00:00<00:00, 528.88 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "188 training tasks were filtered out because they exceed the 2048 token limit.\n",
      "The filtered training dataset contains 132 tasks for fine-tuning.\n",
      "42 evaluation tasks were filtered out because they exceed the 2048 token limit.\n",
      "The filtered evaluation dataset contains 38 tasks for evaluation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the maximum number of tokens allowed\n",
    "max_tokens = 2048\n",
    "\n",
    "# Function to calculate the number of tokens in a text\n",
    "def count_tokens(text):\n",
    "    \"\"\"\n",
    "    Calculate the number of tokens in a given text using the tokenizer.\n",
    "\n",
    "    Parameters:\n",
    "    text (str): The input text to be tokenized.\n",
    "\n",
    "    Returns:\n",
    "    int: The number of tokens in the input text.\n",
    "    \"\"\"\n",
    "    return len(tokenizer.encode(text))\n",
    "\n",
    "# Filter the dataset to include only tasks with a number of tokens within the allowed limit\n",
    "filtered_train_dataset = dataset['train'].filter(lambda x: count_tokens(x['text']) <= max_tokens)\n",
    "filtered_eval_dataset = dataset['test'].filter(lambda x: count_tokens(x['text']) <= max_tokens)\n",
    "\n",
    "# Calculate the number of tasks filtered out\n",
    "filtered_out_train_tasks = len(dataset['train']) - len(filtered_train_dataset)\n",
    "filtered_out_eval_tasks = len(dataset['test']) - len(filtered_eval_dataset)\n",
    "\n",
    "# Print the number of tasks filtered out and the remaining tasks\n",
    "print(f'{filtered_out_train_tasks} training tasks were filtered out because they exceed the {max_tokens} token limit.')\n",
    "print(f'The filtered training dataset contains {len(filtered_train_dataset)} tasks for fine-tuning.')\n",
    "print(f'{filtered_out_eval_tasks} evaluation tasks were filtered out because they exceed the {max_tokens} token limit.')\n",
    "print(f'The filtered evaluation dataset contains {len(filtered_eval_dataset)} tasks for evaluation.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fcd08cbe-ffdc-4365-b439-1706a6d51183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant\n",
      "\n",
      "I've solved the puzzle based on the rules learned from the training data.\n"
     ]
    }
   ],
   "source": [
    "torch.backends.cuda.enable_mem_efficient_sdp(False)\n",
    "torch.backends.cuda.enable_flash_sdp(False)\n",
    "pipeline = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "terminators = [\n",
    "    pipeline.tokenizer.eos_token_id,\n",
    "    pipeline.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "]\n",
    "\n",
    "# pipeline(dataset['train'][0]['text'], max_new_tokens=1000, return_full_text=False)\n",
    "\n",
    "prompt = filtered_eval_dataset[0]['text']\n",
    "\n",
    "outputs = pipeline(\n",
    "    prompt,\n",
    "    max_new_tokens=512,\n",
    "    eos_token_id=terminators,\n",
    "    do_sample=True,\n",
    "    temperature=0.6,\n",
    "    top_p=0.9\n",
    ")\n",
    "print(outputs[0][\"generated_text\"][len(prompt):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f7cc8334-c265-4a5b-adf7-dced4ae607d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure LoRA (Low-Rank Adaptation) for fine-tuning the model\n",
    "peft_config = LoraConfig(\n",
    "        lora_alpha=64,  # Scaling factor for the low-rank matrices\n",
    "        lora_dropout=0.05,  # Dropout rate to apply to the low-rank matrices\n",
    "        r=4,  # Rank of the low-rank matrices\n",
    "        bias=\"none\",  # Type of bias to use (none, all, or some specific layers)\n",
    "        task_type=\"CAUSAL_LM\",  # Specify the type of task (e.g., CAUSAL_LM for causal language modeling)\n",
    "        target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",  # List of modules to apply LoRA to\n",
    "                        \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    ")\n",
    "\n",
    "# Explanation of LoRA Configuration Parameters:\n",
    "# lora_alpha: Controls the scaling of the low-rank adaptation, helping to balance between original weights and the adapted ones.\n",
    "# lora_dropout: Introduces dropout to the low-rank adaptation matrices, aiding in regularization.\n",
    "# r: Defines the rank of the low-rank matrices, controlling the number of parameters added.\n",
    "# bias: Determines whether and where to apply bias in the adapted model.\n",
    "# task_type: Specifies the type of task for fine-tuning (CAUSAL_LM for causal language modeling in this case).\n",
    "# target_modules: Lists the specific modules of the model where LoRA will be applied, focusing the adaptation on critical components.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "190a8620-f13c-448e-8ec0-b05a447e68ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n"
     ]
    }
   ],
   "source": [
    "# Define the output directory for the fine-tuned model\n",
    "output_dir=\"llama3_8b_arc_v01\"\n",
    "\n",
    "sft_config = SFTConfig(\n",
    "    output_dir=output_dir,  # Directory to save the fine-tuned model and checkpoints\n",
    "    eval_strategy=\"steps\",  # Evaluate the model at regular steps\n",
    "    do_eval=True,  # Perform evaluation during training\n",
    "    optim=\"paged_adamw_8bit\",  # Optimizer to use for training (paged AdamW with 8-bit precision)\n",
    "    per_device_train_batch_size=1,  # Training batch size per device\n",
    "    gradient_accumulation_steps=8,  # Accumulate gradients over multiple steps to effectively increase batch size\n",
    "    per_device_eval_batch_size=1,  # Evaluation batch size per device\n",
    "    log_level=\"debug\",  # Logging level (debug for detailed logs)\n",
    "    save_steps=250,  # Save model checkpoint every 100 steps\n",
    "    logging_steps=10,  # Log training metrics every step\n",
    "    learning_rate=8e-6,  # Learning rate for the optimizer\n",
    "    eval_steps=250,  # Evaluate the model every 100 steps\n",
    "    max_steps=750,  # Maximum number of training steps\n",
    "    num_train_epochs=3,  # Number of training epochs\n",
    "    warmup_steps=10,  # Number of warmup steps for learning rate scheduler\n",
    "    lr_scheduler_type=\"cosine\",  # Type of learning rate scheduler (cosine annealing)\n",
    "    fp16=True,  # Use 16-bit floating point precision for training\n",
    "    bf16=False,  # Do not use bfloat16 precision\n",
    "    max_grad_norm=0.3,  # Maximum gradient norm for gradient clipping\n",
    "    gradient_checkpointing=True,  # Use gradient checkpointing to save memory\n",
    "    gradient_checkpointing_kwargs={'use_reentrant':False},  # Arguments for gradient checkpointing\n",
    "    ######\n",
    "    dataset_text_field=\"text\", # The field in the dataset containing the text data\n",
    "    max_seq_length=max_tokens,  # The maximum sequence length for tokenization\n",
    "    packing=False,\n",
    "    report_to=\"none\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b0945746-cb5c-49a0-bac6-299aede67635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable Weights & Biases (wandb) for tracking the training process\n",
    "os.environ['WANDB_DISABLED'] = 'true'\n",
    "#os.environ[\"WANDB_PROJECT\"] = \"llama3_8b_ARC\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8cddc526-3c18-4f0a-868a-75021b01ffcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "Map: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 132/132 [00:00<00:00, 2579.13 examples/s]\n",
      "Map: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 38/38 [00:00<00:00, 2684.26 examples/s]\n",
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "Using auto half precision backend\n",
      "Currently training with a batch size of: 1\n",
      "***** Running training *****\n",
      "  Num examples = 132\n",
      "  Num Epochs = 47\n",
      "  Instantaneous batch size per device = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 8\n",
      "  Total optimization steps = 750\n",
      "  Number of trainable parameters = 10,485,760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 10,485,760 || all params: 8,040,747,008 || trainable%: 0.1304\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='750' max='750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [750/750 1:30:14, Epoch 45/47]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.107900</td>\n",
       "      <td>0.181301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.038100</td>\n",
       "      <td>0.250031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.022100</td>\n",
       "      <td>0.294249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 38\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to llama3_8b_arc_v01/checkpoint-250\n",
      "loading configuration file config.json from cache at /home/vishwak/.cache/huggingface/hub/models--meta-llama--Meta-Llama-3-8B-instruct/snapshots/e1945c40cd546c78e41f1151f4db032b271faeaa/config.json\n",
      "Model config LlamaConfig {\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": 128009,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 14336,\n",
      "  \"max_position_embeddings\": 8192,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.42.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128256\n",
      "}\n",
      "\n",
      "tokenizer config file saved in llama3_8b_arc_v01/checkpoint-250/tokenizer_config.json\n",
      "Special tokens file saved in llama3_8b_arc_v01/checkpoint-250/special_tokens_map.json\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 38\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to llama3_8b_arc_v01/checkpoint-500\n",
      "loading configuration file config.json from cache at /home/vishwak/.cache/huggingface/hub/models--meta-llama--Meta-Llama-3-8B-instruct/snapshots/e1945c40cd546c78e41f1151f4db032b271faeaa/config.json\n",
      "Model config LlamaConfig {\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": 128009,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 14336,\n",
      "  \"max_position_embeddings\": 8192,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.42.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128256\n",
      "}\n",
      "\n",
      "tokenizer config file saved in llama3_8b_arc_v01/checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in llama3_8b_arc_v01/checkpoint-500/special_tokens_map.json\n",
      "\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 38\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to llama3_8b_arc_v01/checkpoint-750\n",
      "loading configuration file config.json from cache at /home/vishwak/.cache/huggingface/hub/models--meta-llama--Meta-Llama-3-8B-instruct/snapshots/e1945c40cd546c78e41f1151f4db032b271faeaa/config.json\n",
      "Model config LlamaConfig {\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": 128009,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 14336,\n",
      "  \"max_position_embeddings\": 8192,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.42.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128256\n",
      "}\n",
      "\n",
      "tokenizer config file saved in llama3_8b_arc_v01/checkpoint-750/tokenizer_config.json\n",
      "Special tokens file saved in llama3_8b_arc_v01/checkpoint-750/special_tokens_map.json\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "loading configuration file config.json from cache at /home/vishwak/.cache/huggingface/hub/models--meta-llama--Meta-Llama-3-8B-instruct/snapshots/e1945c40cd546c78e41f1151f4db032b271faeaa/config.json\n",
      "Model config LlamaConfig {\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": 128009,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 14336,\n",
      "  \"max_position_embeddings\": 8192,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": null,\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"bfloat16\",\n",
      "  \"transformers_version\": \"4.42.0.dev0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128256\n",
      "}\n",
      "\n",
      "tokenizer config file saved in llama3_8b_arc_v01/tokenizer_config.json\n",
      "Special tokens file saved in llama3_8b_arc_v01/special_tokens_map.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer saved to llama3_8b_arc_v01\n"
     ]
    }
   ],
   "source": [
    "torch.backends.cuda.enable_mem_efficient_sdp(False)\n",
    "torch.backends.cuda.enable_flash_sdp(False)\n",
    "# Set up the SFTTrainer for fine-tuning the model\n",
    "# Define the output directory for the fine-tuned model\n",
    "output_dir=\"../models/finetune/llama3_8b_arc_v02\"\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "        model=model,  # The pre-trained model to be fine-tuned\n",
    "        train_dataset=filtered_train_dataset,  # The training dataset\n",
    "        eval_dataset=filtered_eval_dataset,  # The evaluation dataset\n",
    "        peft_config=peft_config,  # LoRA configuration for parameter-efficient fine-tuning\n",
    "        tokenizer=tokenizer,  # The tokenizer for the model\n",
    "        args=sft_config,  # Training arguments configuration\n",
    ")\n",
    "\n",
    "# Print the number of trainable parameters in the model\n",
    "trainer.model.print_trainable_parameters()\n",
    "\n",
    "# Start the training process\n",
    "trainer.train()\n",
    "\n",
    "# Save the fine-tuned model\n",
    "trainer.model.save_pretrained(output_dir)\n",
    "\n",
    "# Save the tokenizer\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "print(f\"Model and tokenizer saved to {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258e9212-9ab4-449f-9eae-3885218ef5ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d870de-619a-4391-9ab0-713fb152d78f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
